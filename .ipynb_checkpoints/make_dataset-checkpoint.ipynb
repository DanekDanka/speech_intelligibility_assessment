{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb408221",
   "metadata": {},
   "source": [
    "# Обзор датасета и создание нового"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a8cc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pystoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab19d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import wavfile\n",
    "from scipy.signal import hilbert, find_peaks, medfilt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ec9c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_wav_folder = '/home/danya/datasets/speech_thesisis/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d6d66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import wavfile\n",
    "\n",
    "# Чтение WAV файла\n",
    "sample_rate, audio_data = wavfile.read(path_to_wav_folder + 'Рина_8-1м.wav')\n",
    "\n",
    "# Выбор сегмента данных\n",
    "segment = audio_data[140000:200000]\n",
    "\n",
    "# Если аудио стерео, берем только один канал\n",
    "if len(segment.shape) > 1:\n",
    "    segment = segment[:, 0]\n",
    "\n",
    "# Вычисление БПФ\n",
    "fft_result = np.fft.fft(segment)\n",
    "fft_magnitude = np.abs(fft_result)\n",
    "\n",
    "# Создание массива частот\n",
    "n = len(segment)\n",
    "freqs = np.fft.fftfreq(n, 1/sample_rate)\n",
    "\n",
    "# Берем только положительные частоты (первую половину)\n",
    "positive_freq_idx = freqs > 0\n",
    "freqs_positive = freqs[positive_freq_idx]\n",
    "fft_positive = fft_magnitude[positive_freq_idx]\n",
    "\n",
    "# Находим частоту с максимальной амплитудой (основная частота)\n",
    "max_amp_idx = np.argmax(fft_positive)\n",
    "dominant_frequency = freqs_positive[max_amp_idx]\n",
    "\n",
    "print(f\"Основная частота сигнала: {dominant_frequency:.2f} Hz\")\n",
    "\n",
    "# Визуализация\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(segment)\n",
    "plt.title('Временная область')\n",
    "plt.xlabel('Отсчеты')\n",
    "plt.ylabel('Амплитуда')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(freqs_positive, fft_positive)\n",
    "plt.axvline(x=dominant_frequency, color='r', linestyle='--', label=f'Основная частота: {dominant_frequency:.2f} Hz')\n",
    "plt.title('Частотная область (БПФ)')\n",
    "plt.xlabel('Частота (Hz)')\n",
    "plt.ylabel('Амплитуда')\n",
    "plt.legend()\n",
    "plt.xlim(0, 5000)  # Ограничиваем диапазон для лучшей видимости\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5988d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_waveform_with_envelope(waveform, sample_rate, title):\n",
    "    # Нормализация сигнала\n",
    "    waveform = waveform / np.max(np.abs(waveform))\n",
    "    \n",
    "    # Параметры для оконной функции\n",
    "    window_size = int(0.02 * sample_rate)  # 20 мс окно\n",
    "    hop_size = int(window_size / 4)  # 25% перекрытие\n",
    "    \n",
    "    # Метод 1: Огибающая через скользящее максимальное окно (как на картинке)\n",
    "    amplitude_envelope_windowed = np.zeros_like(waveform)\n",
    "    \n",
    "    for i in range(0, len(waveform) - window_size, hop_size):\n",
    "        window = waveform[i:i + window_size]\n",
    "        max_val = np.max(np.abs(window))\n",
    "        amplitude_envelope_windowed[i:i + hop_size] = max_val\n",
    "    \n",
    "    # Заполняем оставшиеся samples\n",
    "    if len(waveform) % hop_size != 0:\n",
    "        remaining = len(waveform) - (len(waveform) // hop_size) * hop_size\n",
    "        amplitude_envelope_windowed[-remaining:] = amplitude_envelope_windowed[-(remaining + hop_size)]\n",
    "    \n",
    "    # Сглаживаем медианным фильтром\n",
    "    amplitude_envelope_windowed = medfilt(amplitude_envelope_windowed, kernel_size=window_size//10)\n",
    "    \n",
    "    # Метод 2: Классическая огибающая Гильберта для сравнения\n",
    "    analytic_signal = hilbert(waveform)\n",
    "    amplitude_envelope_hilbert = np.abs(analytic_signal)\n",
    "    \n",
    "    # Создание временной оси в секундах\n",
    "    time = np.arange(len(waveform)) / sample_rate\n",
    "    \n",
    "    # Построение графика\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    # Осциллограмма\n",
    "    plt.plot(time, waveform, label='Осциллограмма', alpha=0.7, color='blue', linewidth=0.8)\n",
    "    \n",
    "    # Огибающая через оконную функцию (как на картинке)\n",
    "    plt.plot(time, amplitude_envelope_windowed, label='Огибающая (оконная)', color='red', linewidth=2)\n",
    "    \n",
    "    # Классическая огибающая Гильберта (для сравнения)\n",
    "    plt.plot(time, amplitude_envelope_hilbert, label='Огибающая (Гильберт)', color='orange', linewidth=1.5, alpha=0.7)\n",
    "    \n",
    "    plt.title(title)\n",
    "    plt.xlabel('Время (с)')\n",
    "    plt.ylabel('Амплитуда')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "\n",
    "def plot_waveform_with_envelope_simple(waveform, sample_rate, title):\n",
    "    \"\"\"Упрощенная версия только с оконной огибающей как на картинке\"\"\"\n",
    "    # Нормализация сигнала\n",
    "    waveform = waveform / np.max(np.abs(waveform))\n",
    "    \n",
    "    # Параметры оконной функции\n",
    "    window_size = int(0.01 * sample_rate)  # 10 мс окно для более точного отслеживания\n",
    "    hop_size = max(1, window_size // 8)    # Маленький шаг для плавности\n",
    "    \n",
    "    # Создаем огибающую через оконное максимальное значение\n",
    "    envelope = np.zeros(len(waveform))\n",
    "    \n",
    "    for i in range(0, len(waveform), hop_size):\n",
    "        end_idx = min(i + window_size, len(waveform))\n",
    "        window = waveform[i:end_idx]\n",
    "        if len(window) > 0:\n",
    "            max_val = np.max(np.abs(window))\n",
    "            # Заполняем текущий сегмент максимальным значением\n",
    "            fill_end = min(i + hop_size, len(waveform))\n",
    "            envelope[i:fill_end] = max_val\n",
    "    \n",
    "    # Сглаживание огибающей\n",
    "    smooth_window = max(1, window_size // 4)\n",
    "    if smooth_window > 1:\n",
    "        envelope = np.convolve(envelope, np.ones(smooth_window)/smooth_window, mode='same')\n",
    "    \n",
    "    # Создание временной оси в секундах\n",
    "    time = np.arange(len(waveform)) / sample_rate\n",
    "    \n",
    "    # Построение графика\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(time, waveform, label='Осциллограмма', alpha=0.5, color='blue', linewidth=1)\n",
    "    plt.plot(time, envelope, label='Огибающая', color='red', linewidth=2)\n",
    "    \n",
    "    plt.title(title)\n",
    "    plt.xlabel('Время (с)')\n",
    "    plt.ylabel('Амплитуда')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "\n",
    "def process_wav_files(folder_path, method='simple'):\n",
    "    # Получаем список всех WAV-файлов в директории\n",
    "    wav_files = [f for f in os.listdir(folder_path) if f.lower().endswith('.wav')]\n",
    "    \n",
    "    if not wav_files:\n",
    "        print(\"В указанной директории не найдено WAV-файлов.\")\n",
    "        return\n",
    "    \n",
    "    for wav_file in wav_files:\n",
    "        file_path = os.path.join(folder_path, wav_file)\n",
    "        \n",
    "        try:\n",
    "            # Загружаем WAV-файл\n",
    "            sample_rate, audio_data = wavfile.read(file_path)\n",
    "            \n",
    "            # Если аудио стерео, берем только один канал\n",
    "            if len(audio_data.shape) > 1:\n",
    "                audio_data = audio_data[:, 0]\n",
    "            \n",
    "            len_data = len(audio_data) // 10\n",
    "            \n",
    "            print(f\"Обработка файла: {wav_file}\")\n",
    "            print(f\"Частота дискретизации: {sample_rate} Гц\")\n",
    "            print(f\"Длительность: {len(audio_data)/sample_rate:.2f} секунд\")\n",
    "            \n",
    "            # Строим график в зависимости от выбранного метода\n",
    "            if method == 'simple':\n",
    "                plot_waveform_with_envelope_simple(audio_data[:len_data], sample_rate, f'Осциллограмма и огибающая\\n{wav_file}')\n",
    "            else:\n",
    "                plot_waveform_with_envelope(audio_data[:len_data], sample_rate, f'Осциллограмма и огибающая\\n{wav_file}')\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Ошибка при обработке файла {wav_file}: {str(e)}\")\n",
    "    \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99006a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_wav_files(path_to_wav_folder, method='simple')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53feb487",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import wavfile\n",
    "import IPython.display as ipd\n",
    "from pystoi import stoi\n",
    "from scipy.signal import spectrogram, find_peaks, butter, filtfilt\n",
    "import sys\n",
    "\n",
    "# Добавляем путь к модулю с VAD функциями\n",
    "# sys.path.append('/path/to/your/module')  # раскомментируйте и укажите правильный путь\n",
    "from exercises_blank import energy_gmm_vad\n",
    "\n",
    "def gauss_pdf(x, mu, sigma):\n",
    "    \"\"\"Функция плотности вероятности гауссовского распределения\"\"\"\n",
    "    return (1.0 / (sigma * np.sqrt(2 * np.pi))) * np.exp(-0.5 * ((x - mu) / sigma) ** 2)\n",
    "\n",
    "def bandpass_filter(signal, sample_rate, lowcut=750, highcut=850, order=4):\n",
    "    \"\"\"Бандассный фильтр для выделения тона 800 Гц\"\"\"\n",
    "    nyquist = 0.5 * sample_rate\n",
    "    low = lowcut / nyquist\n",
    "    high = highcut / nyquist\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    return filtfilt(b, a, signal)\n",
    "\n",
    "def detect_800hz_tone(signal, sample_rate, tone_freq=800, threshold=0.3, min_duration=0.5):\n",
    "    \"\"\"\n",
    "    Обнаруживает тон 800 Гц в сигнале и возвращает индекс ОКОНЧАНИЯ тона\n",
    "    \"\"\"\n",
    "    # Применяем bandpass фильтр вокруг 800 Гц\n",
    "    filtered_signal = bandpass_filter(signal, sample_rate, tone_freq-50, tone_freq+50)\n",
    "    \n",
    "    # Вычисляем огибающую отфильтрованного сигнала\n",
    "    envelope = np.abs(filtered_signal)\n",
    "    \n",
    "    # Сглаживаем огибающую\n",
    "    smooth_window = int(0.02 * sample_rate)  # 20 мс\n",
    "    if smooth_window > 1:\n",
    "        envelope_smooth = np.convolve(envelope, np.ones(smooth_window)/smooth_window, mode='same')\n",
    "    else:\n",
    "        envelope_smooth = envelope\n",
    "    \n",
    "    # Нормализуем огибающую\n",
    "    envelope_norm = envelope_smooth / np.max(envelope_smooth)\n",
    "    \n",
    "    # Находим участки где огибающая превышает порог\n",
    "    tone_mask = envelope_norm > threshold\n",
    "    \n",
    "    # Находим непрерывные сегменты тона\n",
    "    tone_segments = []\n",
    "    in_tone = False\n",
    "    start_idx = 0\n",
    "    \n",
    "    for i in range(len(tone_mask)):\n",
    "        if tone_mask[i] and not in_tone:\n",
    "            # Начало тона\n",
    "            in_tone = True\n",
    "            start_idx = i\n",
    "        elif not tone_mask[i] and in_tone:\n",
    "            # Конец тона\n",
    "            in_tone = False\n",
    "            end_idx = i\n",
    "            duration = (end_idx - start_idx) / sample_rate\n",
    "            if duration >= min_duration:\n",
    "                tone_segments.append((start_idx, end_idx, duration))\n",
    "    \n",
    "    # Если тон продолжается до конца файла\n",
    "    if in_tone:\n",
    "        duration = (len(tone_mask) - start_idx) / sample_rate\n",
    "        if duration >= min_duration:\n",
    "            tone_segments.append((start_idx, len(tone_mask), duration))\n",
    "    \n",
    "    if tone_segments:\n",
    "        # Сортируем сегменты по энергии (самый сильный тон)\n",
    "        tone_segments.sort(key=lambda x: np.mean(envelope_norm[x[0]:x[1]]), reverse=True)\n",
    "        \n",
    "        # Берем самый сильный тон\n",
    "        best_tone_start, best_tone_end, best_duration = tone_segments[0]\n",
    "        \n",
    "        # Возвращаем КОНЕЦ тона + небольшой запас\n",
    "        tone_end_sample = min(best_tone_end + int(0.1 * sample_rate), len(signal))\n",
    "        \n",
    "        print(f\"Обнаружен тон {tone_freq} Гц:\")\n",
    "        print(f\"  - Начало: {best_tone_start/sample_rate:.2f} сек\")\n",
    "        print(f\"  - Окончание: {best_tone_end/sample_rate:.2f} сек\") \n",
    "        print(f\"  - Длительность: {best_duration:.2f} сек\")\n",
    "        print(f\"  - Анализ начнется с: {tone_end_sample/sample_rate:.2f} сек\")\n",
    "        \n",
    "        return tone_end_sample\n",
    "    else:\n",
    "        print(f\"Тон {tone_freq} Гц не обнаружен, используем весь сигнал\")\n",
    "        return 0\n",
    "\n",
    "def extract_speech_segments(signal, vad_markup, sample_rate, min_silence_duration=0.1):\n",
    "    \"\"\"\n",
    "    Извлекает речевые сегменты и соединяет их в один непрерывный сигнал\n",
    "    \"\"\"\n",
    "    # Находим границы речевых сегментов\n",
    "    speech_segments = []\n",
    "    in_speech = False\n",
    "    start_idx = 0\n",
    "    \n",
    "    # Добавляем небольшой буфер для плавности\n",
    "    silence_samples = int(min_silence_duration * sample_rate)\n",
    "    \n",
    "    for i in range(len(vad_markup)):\n",
    "        if vad_markup[i] == 1 and not in_speech:\n",
    "            # Начало речевого сегмента\n",
    "            in_speech = True\n",
    "            start_idx = max(0, i - silence_samples // 4)\n",
    "        elif vad_markup[i] == 0 and in_speech:\n",
    "            # Проверяем, достаточно ли длинная пауза\n",
    "            if i + silence_samples < len(vad_markup):\n",
    "                if np.all(vad_markup[i:i+silence_samples] == 0):\n",
    "                    in_speech = False\n",
    "                    end_idx = min(len(signal), i + silence_samples // 4)\n",
    "                    speech_segments.append(signal[start_idx:end_idx])\n",
    "            else:\n",
    "                # Конец файла\n",
    "                in_speech = False\n",
    "                speech_segments.append(signal[start_idx:i])\n",
    "    \n",
    "    # Если последний сегмент продолжается до конца файла\n",
    "    if in_speech:\n",
    "        speech_segments.append(signal[start_idx:])\n",
    "    \n",
    "    # Объединяем все сегменты в один сигнал\n",
    "    if speech_segments:\n",
    "        continuous_speech = np.concatenate(speech_segments)\n",
    "        \n",
    "        # Добавляем короткие паузы между сегментами для естественности\n",
    "        pause_duration = int(0.05 * sample_rate)\n",
    "        pause = np.zeros(pause_duration)\n",
    "        \n",
    "        final_speech = speech_segments[0]\n",
    "        for segment in speech_segments[1:]:\n",
    "            final_speech = np.concatenate([final_speech, pause, segment])\n",
    "        \n",
    "        return final_speech, speech_segments\n",
    "    else:\n",
    "        return np.array([]), []\n",
    "\n",
    "def apply_vad_filter(signal, vad_markup):\n",
    "    \"\"\"Применяет VAD разметку к сигналу - обнуляет неречевые участки\"\"\"\n",
    "    signal_filtered = signal.copy()\n",
    "    signal_filtered[vad_markup == 0] = 0\n",
    "    return signal_filtered\n",
    "\n",
    "def extract_audio_after_tone(signal, sample_rate, tone_end_sample, duration_sec=10):\n",
    "    \"\"\"Извлекает первые 10 секунд аудио сигнала ПОСЛЕ окончания тона 800 Гц\"\"\"\n",
    "    start_sample = tone_end_sample\n",
    "    end_sample = min(len(signal), start_sample + duration_sec * sample_rate)\n",
    "    \n",
    "    if end_sample > start_sample:\n",
    "        return signal[start_sample:end_sample], start_sample, end_sample\n",
    "    else:\n",
    "        return np.array([]), start_sample, start_sample\n",
    "\n",
    "def load_audio_file(file_path):\n",
    "    \"\"\"Загружает аудио файл\"\"\"\n",
    "    try:\n",
    "        sample_rate, audio_data = wavfile.read(file_path)\n",
    "        \n",
    "        if len(audio_data.shape) > 1:\n",
    "            audio_data = audio_data[:, 0]\n",
    "        \n",
    "        audio_data = audio_data.astype('float32')\n",
    "        audio_data = audio_data / np.max(np.abs(audio_data))\n",
    "        \n",
    "        # Для всех файлов берем достаточно данных для анализа 10 секунд после тона\n",
    "        # Для Рина_8-1м.wav тона может быть позже, поэтому берем больше данных\n",
    "        if '8-1м' in file_path:\n",
    "            max_duration = 25  # 25 секунд для файла с поздним тоном\n",
    "        else:\n",
    "            max_duration = 15  # 15 секунд для остальных файлов\n",
    "            \n",
    "        max_samples = min(len(audio_data), max_duration * sample_rate)\n",
    "        audio_segment = audio_data[:max_samples]\n",
    "        \n",
    "        print(f\"  - Загружено: {len(audio_segment)/sample_rate:.2f} сек\")\n",
    "        \n",
    "        return audio_segment, sample_rate\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка при загрузке файла {file_path}: {str(e)}\")\n",
    "        return None, None\n",
    "\n",
    "def process_file_with_vad_after_tone(file_path):\n",
    "    \"\"\"Обработка файла с обнаружением ОКОНЧАНИЯ тона 800 Гц и применением VAD только к речи после тона\"\"\"\n",
    "    try:\n",
    "        sample_rate, audio_data = wavfile.read(file_path)\n",
    "        \n",
    "        if len(audio_data.shape) > 1:\n",
    "            audio_data = audio_data[:, 0]\n",
    "        \n",
    "        audio_data = audio_data.astype('float32')\n",
    "        audio_data = audio_data / np.max(np.abs(audio_data))\n",
    "        \n",
    "        # Для всех файлов берем достаточно данных для анализа 10 секунд после тона\n",
    "        if '8-1м' in file_path:\n",
    "            max_duration = 25  # 25 секунд для файла с поздним тоном\n",
    "        else:\n",
    "            max_duration = 15  # 15 секунд для остальных файлов\n",
    "            \n",
    "        max_samples = min(len(audio_data), max_duration * sample_rate)\n",
    "        audio_segment = audio_data[:max_samples]\n",
    "        \n",
    "        print(f\"  - Длительность загруженного сигнала: {len(audio_segment)/sample_rate:.2f} сек\")\n",
    "        \n",
    "        # Обнаруживаем ОКОНЧАНИЕ тона 800 Гц\n",
    "        tone_end_sample = detect_800hz_tone(audio_segment, sample_rate)\n",
    "        \n",
    "        # Берем только часть сигнала после ОКОНЧАНИЯ тона\n",
    "        speech_start_sample = tone_end_sample\n",
    "        speech_signal = audio_segment[speech_start_sample:]\n",
    "        \n",
    "        if len(speech_signal) == 0:\n",
    "            print(\"❌ Нет сигнала после тона 800 Гц\")\n",
    "            return None, sample_rate, 0, audio_segment, None, speech_start_sample\n",
    "        \n",
    "        print(f\"  - Длительность сигнала после тона: {len(speech_signal)/sample_rate:.2f} сек\")\n",
    "        \n",
    "        # Получаем VAD разметку для сигнала после тона\n",
    "        vad_markup_speech = energy_gmm_vad(\n",
    "            signal=speech_signal,\n",
    "            window=320,\n",
    "            shift=160,\n",
    "            gauss_pdf=gauss_pdf,\n",
    "            n_realignment=10,\n",
    "            vad_thr=0.5,\n",
    "            mask_size_morph_filt=5\n",
    "        )\n",
    "        \n",
    "        # Создаем полную VAD разметку для всего сигнала (для визуализации)\n",
    "        full_vad_markup = np.zeros_like(audio_segment)\n",
    "        full_vad_markup[speech_start_sample:speech_start_sample + len(vad_markup_speech)] = vad_markup_speech\n",
    "        \n",
    "        # Извлекаем непрерывную речь из части после тона\n",
    "        continuous_speech, speech_segments = extract_speech_segments(speech_signal, vad_markup_speech, sample_rate)\n",
    "        \n",
    "        return continuous_speech, sample_rate, len(speech_segments), audio_segment, full_vad_markup, speech_start_sample\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка при обработке файла {file_path}: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None, None, 0, None, None, 0\n",
    "\n",
    "def calculate_stoi_after_tone(reference_file, processed_files_folder, results):\n",
    "    \"\"\"Вычисление STOI для первых 10 секунд ПОСЛЕ ОКОНЧАНИЯ тона 800 Гц\"\"\"\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"ВЫЧИСЛЕНИЕ STOI МЕТРИКИ (первые 10 секунд ПОСЛЕ ОКОНЧАНИЯ тона 800 Гц)\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    stoi_results = {}\n",
    "    \n",
    "    # Загружаем и обрабатываем эталонный файл\n",
    "    print(f\"Обработка эталонного файла: {os.path.basename(reference_file)}\")\n",
    "    ref_audio, ref_sample_rate = load_audio_file(reference_file)\n",
    "    \n",
    "    if ref_audio is None:\n",
    "        print(f\"❌ Не удалось загрузить эталонный файл\")\n",
    "        return stoi_results\n",
    "    \n",
    "    # Обнаруживаем ОКОНЧАНИЕ тона 800 Гц в эталонном файле\n",
    "    ref_tone_end = detect_800hz_tone(ref_audio, ref_sample_rate)\n",
    "    ref_audio_after_tone, ref_start, ref_end = extract_audio_after_tone(ref_audio, ref_sample_rate, ref_tone_end, duration_sec=10)\n",
    "    \n",
    "    if len(ref_audio_after_tone) == 0:\n",
    "        print(f\"❌ В эталонном файле нет сигнала после тона 800 Гц\")\n",
    "        return stoi_results\n",
    "    \n",
    "    print(f\"Эталонный файл: {os.path.basename(reference_file)}\")\n",
    "    print(f\"Частота дискретизации эталона: {ref_sample_rate} Гц\")\n",
    "    print(f\"Начало анализа: {ref_start/ref_sample_rate:.2f} сек\")\n",
    "    print(f\"Длительность эталона для сравнения: {len(ref_audio_after_tone)/ref_sample_rate:.2f} сек\")\n",
    "    \n",
    "    # Вычисляем STOI для каждого файла (первые 10 секунд после ОКОНЧАНИЯ тона)\n",
    "    for filename, result_data in results.items():\n",
    "        if result_data['original_audio'] is not None and len(result_data['original_audio']) > 0:\n",
    "            try:\n",
    "                # Получаем оригинальный аудио\n",
    "                original_audio = result_data['original_audio']\n",
    "                original_sample_rate = result_data['sample_rate']\n",
    "                speech_start_sample = result_data['speech_start_sample']\n",
    "                \n",
    "                # Извлекаем первые 10 секунд после ОКОНЧАНИЯ тона\n",
    "                test_audio_after_tone, test_start, test_end = extract_audio_after_tone(\n",
    "                    original_audio, original_sample_rate, speech_start_sample, duration_sec=10\n",
    "                )\n",
    "                \n",
    "                if len(test_audio_after_tone) == 0:\n",
    "                    print(f\"{filename}: нет сигнала после тона 800 Гц\")\n",
    "                    stoi_results[filename] = None\n",
    "                    continue\n",
    "                \n",
    "                print(f\"  - Длительность тестового сигнала: {len(test_audio_after_tone)/original_sample_rate:.2f} сек\")\n",
    "                \n",
    "                # Приводим к той же частоте дискретизации, что и эталон\n",
    "                if original_sample_rate != ref_sample_rate:\n",
    "                    from scipy import signal\n",
    "                    num_samples = int(len(test_audio_after_tone) * ref_sample_rate / original_sample_rate)\n",
    "                    test_audio_resampled = signal.resample(test_audio_after_tone, num_samples)\n",
    "                else:\n",
    "                    test_audio_resampled = test_audio_after_tone\n",
    "                \n",
    "                # Обрезаем до минимальной длины (для STOI нужны одинаковой длины)\n",
    "                min_len = min(len(ref_audio_after_tone), len(test_audio_resampled))\n",
    "                ref_segment = ref_audio_after_tone[:min_len]\n",
    "                test_segment = test_audio_resampled[:min_len]\n",
    "                \n",
    "                # Проверяем, что есть достаточная длительность для сравнения\n",
    "                if min_len < ref_sample_rate * 5:  # минимум 5 секунд для более надежного сравнения\n",
    "                    print(f\"{filename}: недостаточная длительность для сравнения ({min_len/ref_sample_rate:.2f} сек)\")\n",
    "                    stoi_results[filename] = None\n",
    "                    continue\n",
    "                \n",
    "                # Вычисляем STOI между сигналами после ОКОНЧАНИЯ тона\n",
    "                stoi_score = stoi(ref_segment, test_segment, ref_sample_rate, extended=False)\n",
    "                stoi_results[filename] = stoi_score\n",
    "                \n",
    "                print(f\"{filename}: STOI = {stoi_score:.4f} (длительность сравнения: {min_len/ref_sample_rate:.2f} сек, начало анализа: {speech_start_sample/original_sample_rate:.2f} сек)\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Ошибка вычисления STOI для {filename}: {e}\")\n",
    "                stoi_results[filename] = None\n",
    "        else:\n",
    "            print(f\"{filename}: нет оригинального аудио для вычисления STOI\")\n",
    "            stoi_results[filename] = None\n",
    "    \n",
    "    return stoi_results\n",
    "\n",
    "def plot_waveform_with_tone_detection(waveform, vad_markup, sample_rate, tone_position, title):\n",
    "    \"\"\"Визуализация осциллограммы с VAD разметкой и отметкой ОКОНЧАНИЯ тона 800 Гц\"\"\"\n",
    "    waveform = waveform / np.max(np.abs(waveform))\n",
    "    time = np.arange(len(waveform)) / sample_rate\n",
    "    tone_time = tone_position / sample_rate\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(14, 8), sharex=True)\n",
    "    \n",
    "    # Верхний график: осциллограмма\n",
    "    ax1.plot(time, waveform, label='Осциллограмма', alpha=0.7, color='blue', linewidth=1)\n",
    "    ax1.axvline(x=tone_time, color='red', linestyle='--', alpha=0.8, linewidth=2, label='Окончание тона 800 Гц')\n",
    "    \n",
    "    # Показываем область для анализа (первые 10 секунд после тона)\n",
    "    analysis_end = min(tone_time + 10, time[-1])\n",
    "    ax1.axvspan(tone_time, analysis_end, alpha=0.2, color='green', label='Область для STOI анализа')\n",
    "    \n",
    "    ax1.set_ylabel('Амплитуда')\n",
    "    ax1.set_title(f'{title}')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Нижний график: VAD разметка\n",
    "    ax2.fill_between(time, 0, vad_markup, alpha=0.7, color='green', label='VAD разметка')\n",
    "    ax2.plot(time, vad_markup, color='darkgreen', linewidth=1)\n",
    "    ax2.axvline(x=tone_time, color='red', linestyle='--', alpha=0.8, linewidth=2, label='Окончание тона 800 Гц')\n",
    "    ax2.set_ylabel('VAD (0/1)')\n",
    "    ax2.set_xlabel('Время (с)')\n",
    "    ax2.set_ylim(-0.1, 1.1)\n",
    "    ax2.set_yticks([0, 1])\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "def process_all_files_with_stoi_after_tone(folder_path, reference_filename=\"Рина_1-1м.wav\"):\n",
    "    \"\"\"Обработка всех файлов и вычисление STOI по первым 10 секундам ПОСЛЕ ОКОНЧАНИЯ тона 800 Гц\"\"\"\n",
    "    wav_files = [f for f in os.listdir(folder_path) if f.lower().endswith('.wav')]\n",
    "    \n",
    "    if not wav_files:\n",
    "        print(\"В указанной директории не найдено WAV-файлов.\")\n",
    "        return\n",
    "    \n",
    "    results = {}\n",
    "    reference_file = os.path.join(folder_path, reference_filename)\n",
    "    \n",
    "    # Проверяем наличие эталонного файла\n",
    "    if not os.path.exists(reference_file):\n",
    "        print(f\"Эталонный файл {reference_filename} не найден в папке!\")\n",
    "        return\n",
    "    \n",
    "    print(f\"ОБРАБОТКА ФАЙЛОВ С ОБНАРУЖЕНИЕМ ОКОНЧАНИЯ ТОНА 800 ГЦ\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    # Обрабатываем все файлы\n",
    "    for wav_file in wav_files:\n",
    "        file_path = os.path.join(folder_path, wav_file)\n",
    "        print(f\"\\nОбработка: {wav_file}\")\n",
    "        \n",
    "        # Получаем обработанный сигнал с обнаружением ОКОНЧАНИЯ тона\n",
    "        continuous_speech, sample_rate, num_segments, original_audio, vad_markup, speech_start = process_file_with_vad_after_tone(file_path)\n",
    "        \n",
    "        results[wav_file] = {\n",
    "            'continuous_speech': continuous_speech,\n",
    "            'original_audio': original_audio,\n",
    "            'sample_rate': sample_rate,\n",
    "            'num_segments': num_segments,\n",
    "            'vad_markup': vad_markup,\n",
    "            'speech_start_sample': speech_start\n",
    "        }\n",
    "        \n",
    "        if original_audio is not None:\n",
    "            print(f\"  - Начало анализа после тона: {speech_start/sample_rate:.2f} сек\")\n",
    "            print(f\"  - Речевых сегментов после VAD: {num_segments}\")\n",
    "            \n",
    "            # Показываем график с обнаружением ОКОНЧАНИЯ тона\n",
    "            fig = plot_waveform_with_tone_detection(\n",
    "                original_audio, vad_markup, sample_rate, speech_start,\n",
    "                f'{wav_file} - Обнаружение окончания тона 800 Гц и VAD\\n(первые 10 секунд после тона для STOI)'\n",
    "            )\n",
    "            plt.show()\n",
    "        else:\n",
    "            print(f\"  - ❌ Не удалось обработать файл\")\n",
    "    \n",
    "    # Вычисляем STOI для первых 10 секунд после ОКОНЧАНИЯ тона\n",
    "    stoi_results = calculate_stoi_after_tone(reference_file, folder_path, results)\n",
    "    \n",
    "    # Выводим итоговую таблицу результатов\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"ИТОГОВЫЕ РЕЗУЛЬТАТЫ STOI (первые 10 секунд ПОСЛЕ ОКОНЧАНИЯ тона 800 Гц)\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    valid_results = {k: v for k, v in stoi_results.items() if v is not None}\n",
    "    \n",
    "    for filename, score in stoi_results.items():\n",
    "        if score is not None:\n",
    "            print(f\"{filename}: STOI = {score:.4f}\")\n",
    "        else:\n",
    "            print(f\"{filename}: STOI = N/A\")\n",
    "    \n",
    "    if valid_results:\n",
    "        avg_stoi = np.mean(list(valid_results.values()))\n",
    "        print(f\"\\nСредний STOI: {avg_stoi:.4f}\")\n",
    "        \n",
    "        # Находим лучший и худший результаты\n",
    "        best_file = max(valid_results.items(), key=lambda x: x[1])\n",
    "        worst_file = min(valid_results.items(), key=lambda x: x[1])\n",
    "        print(f\"Лучший результат: {best_file[0]} - STOI = {best_file[1]:.4f}\")\n",
    "        print(f\"Худший результат: {worst_file[0]} - STOI = {worst_file[1]:.4f}\")\n",
    "    \n",
    "    # Строим график результатов STOI\n",
    "    if valid_results:\n",
    "        plot_stoi_results(valid_results)\n",
    "    \n",
    "    return results, stoi_results\n",
    "\n",
    "def plot_stoi_results(stoi_results):\n",
    "    \"\"\"Визуализация результатов STOI\"\"\"\n",
    "    valid_results = {k: v for k, v in stoi_results.items() if v is not None}\n",
    "    \n",
    "    if not valid_results:\n",
    "        print(\"Нет данных для построения графика STOI\")\n",
    "        return\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    files = list(valid_results.keys())\n",
    "    scores = list(valid_results.values())\n",
    "    \n",
    "    # Используем разные цвета для эталонного файла\n",
    "    colors = ['lightblue' if 'Рина_1-1м' not in file else 'gold' for file in files]\n",
    "    \n",
    "    bars = plt.bar(files, scores, color=colors, alpha=0.7)\n",
    "    plt.axhline(y=0.5, color='red', linestyle='--', alpha=0.7, label='Порог 0.5')\n",
    "    plt.axhline(y=0.75, color='orange', linestyle='--', alpha=0.7, label='Порог 0.75')\n",
    "    \n",
    "    avg_score = np.mean(scores)\n",
    "    plt.axhline(y=avg_score, color='green', linestyle='-', alpha=0.7, label=f'Среднее: {avg_score:.3f}')\n",
    "    \n",
    "    plt.ylabel('STOI Score')\n",
    "    plt.title('Сравнение STOI метрики (первые 10 секунд ПОСЛЕ ОКОНЧАНИЯ тона 800 Гц)')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Добавляем значения на столбцы\n",
    "    for bar, score in zip(bars, scores):\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n",
    "                f'{score:.3f}', ha='center', va='bottom')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# Использование:\n",
    "path_to_wav_folder = '/home/danya/datasets/speech_thesisis/'\n",
    "\n",
    "# Обработать все файлы и вычислить STOI по первым 10 секундам ПОСЛЕ ОКОНЧАНИЯ тона 800 Гц\n",
    "results, stoi_results = process_all_files_with_stoi_after_tone(path_to_wav_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371defed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
